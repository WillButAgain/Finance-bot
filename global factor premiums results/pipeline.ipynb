{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbaseconda429373aa11874990b7c7d63af53f60f3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "import pandas as pd\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from the API (or whatever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['ORCL', 'MSFT', 'TROW', 'HON', 'ADM', 'FISV', 'CERN', 'KO', 'CDNS','ED', 'XRAY', 'FAST', 'DTE', 'ETN', 'SIVB', 'XOM', 'MGM', 'MXIM','WM', 'GD', 'GE', 'LH', 'PBCT', 'CHTR', 'LYB', 'GM', 'IR', 'FRC','FLT', 'IBM', 'NLSN', 'KMI', 'ITT', 'HCA', 'HII', 'KSU', 'MPC','FBHS', 'XYL', 'APTV', 'PSX', 'FB', 'NOW', 'PNR', 'FANG', 'ABBV','NCLH', 'ZTS', 'PEP', 'MO', 'IQV', 'COP', 'PVH', 'CDW', 'NWSA','NWS', 'COTY', 'AMGN', 'SLB', 'TWTR', 'ALLE', 'HLT', 'CVX', 'GOOG','AAPL', 'AMAT', 'INFO', 'ANET', 'SYF', 'CFG', 'KEYS', 'MRO', 'VMC','KHC', 'TXN', 'PYPL', 'EIX', 'HPE', 'FTV', 'UA', 'FTI', 'LW', 'KR','HSY', 'GIS', 'CVS', 'WRB', 'SPGI', 'UTX', 'KMB', 'PG', 'LIN','CAT', 'SO', 'FMC', 'CL', 'BMY', 'DE', 'BA', 'WBA', 'AAL', 'ABT','WRK', 'LMT', 'CAH', 'NEM', 'EXC', 'IP', 'PFE', 'CNP', 'JNJ','EMR', 'PPG', 'GLW', 'MMM', 'PPL', 'MSI', 'MRK', 'CMS', 'FE', 'CINF', 'CHD', 'TXT', 'WEC', 'PEG', 'CTAS', 'XEL', 'HAL', 'EVRG', 'ETR', 'NEE', 'AEP', 'NOC', 'ARNC', 'AEE', 'RTN', 'OKE', 'CMA', 'WHR', 'CPB', 'DOV', 'F', 'BH', 'DIS', 'K', 'L', 'HPQ', 'VAR', 'DUK', 'BAX', 'PNW', 'XRX', 'VNO', 'APD', 'ALK', 'HES', 'FLS', 'OMC', 'HFC', 'HP', 'ATO', 'HRL', 'FITB', 'MAS', 'OXY', 'NUE', 'MTB', 'RF', 'SHW', 'ROL', 'AJG', 'BEN', 'WFC', 'WMB', 'APA', 'NI', 'WY', 'BDX', 'IFF', 'DXC', 'CMI', 'TJX', 'PKI', 'PH', 'JBHT', 'SJM', 'SWK', 'HBAN', 'VFC', 'MCD', 'TFX', 'ES', 'ADP', 'AVY', 'MMC', 'JCI', 'CLX', 'SWKS', 'HST', 'GPC', 'JPM', 'KLAC', 'MCO', 'LRCX', 'UNP', 'HUM', 'TGT', 'LNC', 'BK', 'HRB', 'LEE', 'DHR', 'PIR', 'LLY', 'MKC', 'SYY', 'EFX', 'RHI', 'LEN', 'GWW', 'IPG', 'HAS', 'PHM', 'MU', 'CAG', 'WMT', 'BLL', 'ITW', 'JWN', 'NKE', 'NTRS', 'AFL', 'LUV', 'FRT', 'GPS', 'LNT', 'TAP', 'AXP', 'INTC', 'UDR', 'TRV', 'BAC', 'SNA', 'MDT', 'PCAR', 'PNC', 'FDX', 'CTL', 'LEG', 'ADI', 'AMD', 'NWL', 'PAYX', 'LOW', 'NBL', 'AON', 'CSX', 'TMO', 'LB', 'CI', 'PGR', 'NSC', 'STZ', 'PSA', 'KEY', 'D', 'COO', 'AOS', 'T', 'VZ', 'HD', 'USB', 'AIG', 'WDC', 'MS', 'ITI', 'RJF', 'MYL', 'HOG', 'STZ', 'ECL', 'C', 'STT', 'UNM', 'TIF', 'SYK', 'CCL', 'ABMD', 'PXD', 'SCHW', 'ADBE', 'DRE', 'VTR', 'IEX', 'EA', 'EOG', 'COG', 'CSCO', 'XLNX', 'HOLX', 'REGN', 'AZO', 'AES', 'IDXX', 'ZBRA', 'VRTX', 'ODFL', 'BIIB', 'QCOM', 'KIM', 'GILD', 'PRGO', 'SNPS', 'ROP', 'MHK', 'M', 'KSS', 'BSX', 'DHI', 'STE', 'TSN', 'SBUX', 'INTU', 'AGN', 'CB', 'MCHP', 'RCL', 'ORLY', 'ALL', 'FLIR', 'EQR', 'BWA', 'ATVI', 'UHS', 'REG', 'IT', 'INCY', 'NVR', 'SPG', 'EMN', 'ALB', 'MAA', 'TSCO', 'MLM', 'AVB', 'CPRT', 'AIV', 'ESS', 'COF', 'O', 'DLTR', 'MCK', 'COOP', 'ABC', 'WAB', 'DRI', 'RMD', 'DISH', 'IVZ', 'FCX', 'RE', 'WABC', 'HSIC', 'DVA', 'MLSS', 'NTAP', 'WAT', 'EL', 'HIG', 'CTXS', 'IRM', 'ALXN', 'ANSS', 'TCX', 'NOV', 'ETFC', 'DGX', 'ZION', 'CMT', 'ROK', 'ARE', 'TTWO', 'AMZN', 'APH', 'BXP', 'QRVO', 'AME', 'RL', 'VLO', 'SLG', 'CHRW', 'YUM', 'MTD', 'PLD', 'URI', 'ADSK', 'PWR', 'VRSN', 'BBY', 'MAR', 'AMT', 'SEE', 'CTSH', 'SRE', 'CCI', 'RSG', 'NVDA', 'EBAY', 'GS', 'BKNG', 'JNPR', 'FFIV', 'COST', 'SBAC', 'BLK', 'DVN', 'A', 'AKAM', 'PKG', 'UPS', 'EXPD', 'EW', 'MNST', 'MET', 'ILMN', 'ISRG', 'JKHY', 'TPR', 'ALGN', 'GRMN', 'ADS', 'GPN', 'MDLZ', 'FIS', 'ZBH', 'WLTW', 'MKC', 'ACN', 'PFG', 'ANTM', 'PRU', 'AAP', 'NFLX', 'CNC', 'XEC', 'KMX', 'WYNN', 'CMCSA', 'CME', 'EQIX', 'LEN', 'STX', 'AIZ', 'LKQ', 'CBRE', 'NRG', 'WCG', 'CRM', 'GOOGL', 'EXR', 'MOS', 'DLR', 'FOX', 'FOXA', 'LVS', 'MKTX', 'TAP', 'CE', 'DISCA', 'NDAQ', 'CF', 'EXPE', 'UAA', 'AMP', 'LYV', 'ICE', 'UAL', 'CMG', 'MA', 'TDG', 'WU', 'HBI', 'ROST', 'LDOS', 'BR', 'IPGP', 'TMUS', 'DAL', 'TEL', 'DFS', 'ULTA', 'CXO', 'PM', 'MSCI', 'AWK', 'V', 'DISCK', 'UNH', 'VRSK', 'AVGO', 'FTNT', 'DG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is fucking stupid\n",
    "i=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fetch_data = 0\n",
    "\n",
    "# temp to fetch data, will be done a few times since limited daily api calls\n",
    "path = '/mnt/c/Users/turbo/Python projects/Finance projects/Finance-bot/global factor premiums results/AlphaVantageData.csv'\n",
    "df = pd.read_csv(path, index_col='date') #,index_col=['gvkey','datadate'])\n",
    "\n",
    "if fetch_data:\n",
    "    # keep key secret shhhhhhhhh\n",
    "    from api_key import APIkey\n",
    "    ALPHA_KEY = APIkey.ALPHA_KEY\n",
    "\n",
    "    for symbol in symbols[i:i+5]:\n",
    "        ts = TimeSeries(key=ALPHA_KEY, output_format='pandas')\n",
    "        data, meta_data = ts.get_daily_adjusted(symbol=symbol, outputsize='full') #choose symbol\n",
    "\n",
    "        data = data.rename(columns={\"1. open\": \"open\",\n",
    "                        \"2. high\": \"high\",\n",
    "                        \"3. low\": \"low\",\n",
    "                        \"4. close\": \"close\",\n",
    "                        \"5. adjusted close\" : \"adjusted_close\",\n",
    "                        \"6. volume\" : \"volume\",\n",
    "                        \"7. dividend amount\": \"dividend_amount\",\n",
    "                        \"8. split coefficient\": \"split_coefficient\"})\n",
    "        print(data['adjusted_close'].pct_change().dropna())\n",
    "        df[symbol] = data['adjusted_close'].pct_change().dropna()\n",
    "\n",
    "    # stoOooOoOOoOOoOoopid\n",
    "    i += 5\n",
    "    df.to_csv('AlphaVantageData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove failed queries. i wish it would just throw an error or something, but thats life ig \n",
    "df = df.dropna(axis=1, how='all')\n",
    "# to jax / np style\n",
    "jax_data = jax.numpy.asarray(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum factor: top 20% performing stocks in the last 30 periods\n",
    "A month in this case \n",
    "\n",
    "## Trend factor: all stocks in the last 1 year that have returns over some percent\n",
    "Paper uses zero, i use 10%\n",
    "\n",
    "we do them at the same time because they are so similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "we have 5230 observations\n"
    }
   ],
   "source": [
    "print('we have', jax_data.shape[0], 'observations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for top 20%, needs to be int not percentage unless we want to do the calculation 5000+ times\n",
    "n = jax_data.shape[1]//5\n",
    "\n",
    "total_length = jax_data.shape[0]\n",
    "\n",
    "momentum_window_length = 30\n",
    "momentum_indices_matrix = jnp.arange(total_length-momentum_window_length+1)[:, None] + jnp.arange(momentum_window_length)\n",
    "\n",
    "def compute_momentum(index_vector, n = 3):\n",
    "    mean_vector = jax.numpy.nanmean(jax_data[index_vector], axis=0)\n",
    "    # replace nans with 0% returns, annoying but too stupid to find better solution\n",
    "    mean_vector = jax.numpy.nan_to_num(mean_vector)\n",
    "    indices = jax.numpy.argsort(mean_vector)\n",
    "    return indices\n",
    "\n",
    "trend_window_length = momentum_window_length*12\n",
    "trend_indices_matrix = jnp.arange(total_length-trend_window_length+1)[:, None] + jnp.arange(trend_window_length)\n",
    "\n",
    "@jax.jit\n",
    "def compute_trend(index_vector, returns_cutoff = 0.2):\n",
    "    # TODO(will) try geometric mean\n",
    "    mean_vector = jax.numpy.nanmean(jax_data[index_vector], axis=0)\n",
    "    # replace nans with 0% returns, annoying but too stupid to find better solution\n",
    "    mean_vector = jax.numpy.nan_to_num(mean_vector)\n",
    "    return mean_vector\n",
    "\n",
    "@jax.jit\n",
    "def trend_search(index_vector):\n",
    "    return jax.vmap(compute_trend)(index_vector)\n",
    "\n",
    "def momentum_search(index_vector):\n",
    "    return jax.vmap(compute_momentum)(index_vector)\n",
    "\n",
    "# this returns an array of trailing returns, the period is whatever was specified earlier. again, we do this so we have more control later, like letting a NN \n",
    "# decide the cutoff threshold\n",
    "trends = trend_search(trend_indices_matrix)\n",
    "\n",
    "# this returns an array of indices of the max values, max value being the max of the indices, this gives us more control later for NN stuff\n",
    "momentum = momentum_search(momentum_indices_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonality\n",
    "\n",
    "this one is more of a visual inspection of cumulative returns over multiple large assets and over a vey long period - are they higher over some range than others?\n",
    "we will look by day and by month\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df.index)\n",
    "df = df.set_index(df['datetime'])\n",
    "\n",
    "# monthly, since i am assuming you (me) are blind and will not see the function argument that says this\n",
    "df.groupby(df.index.month).mean().sum(axis=1).plot(title='Monthly')\n",
    "plt.show()\n",
    "\n",
    "# daily, since i am assuming you (me) are blind and will not see the function argument that says this\n",
    "df.groupby(df.index.dayofyear).mean().sum(axis=1).plot(title='Daily')\n",
    "plt.show()\n",
    "\n",
    "# this will act as a lookup table, look at the average return of a given day of the year at each timestep\n",
    "seasonality = df.groupby(df.index.dayofyear).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}